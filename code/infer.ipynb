{"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":66631,"databundleVersionId":8346466,"sourceType":"competition"},{"sourceId":8897601,"sourceType":"datasetVersion","datasetId":5297895},{"sourceId":9098556,"sourceType":"datasetVersion","datasetId":5491003},{"sourceId":9107287,"sourceType":"datasetVersion","datasetId":5383546},{"sourceId":75103,"sourceType":"modelInstanceVersion","modelInstanceId":63082,"modelId":86587}],"dockerImageVersionId":30733,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"},"papermill":{"default_parameters":{},"duration":148.347272,"end_time":"2024-07-10T01:15:35.655682","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2024-07-10T01:13:07.30841","version":"2.5.0"},"widgets":{"application/vnd.jupyter.widget-state+json":{"state":{"0f59addf0d2f40309e025976c382cad8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_268e3946106b4e41849bf11c5a375dac","placeholder":"​","style":"IPY_MODEL_5bb130c471af4927a6644f932ae47523","value":" 2/2 [00:03&lt;00:00,  1.48s/it]"}},"19ef2d43bafa44a8b20dc5230aea5ae4":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1ca042ffa14e4dbebdc66435f7b1f07f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_19ef2d43bafa44a8b20dc5230aea5ae4","placeholder":"​","style":"IPY_MODEL_d8a7714cd80d479e859b6ae31ebce7e5","value":"Loading checkpoint shards: 100%"}},"1d03719518b8423099b8b68a92e449d7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_64ef70cfa9c04764868fa52963323322","placeholder":"​","style":"IPY_MODEL_5e81b324ca1b46a2a96d02bb2acadc0a","value":"Loading checkpoint shards: 100%"}},"1d89705c74d34016bbc1e0601ead825c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d409334237014614bf9ae742597d98ea","placeholder":"​","style":"IPY_MODEL_875758123e4f41f0b5c3fa0cd4fb47c6","value":" 2/2 [01:18&lt;00:00, 34.68s/it]"}},"1ef6d64d40d8461d9e6adddd513089b8":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"268e3946106b4e41849bf11c5a375dac":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"324c2396f44f45c89d9ec264007ef9ff":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"5bb130c471af4927a6644f932ae47523":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5d243712a1a545e99fa858b0cf19831d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5e81b324ca1b46a2a96d02bb2acadc0a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"64ef70cfa9c04764868fa52963323322":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"68ae4b02a13f4570ad729c437ebd28ee":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_1ca042ffa14e4dbebdc66435f7b1f07f","IPY_MODEL_81b4a9a7cde64b17856b89dbd238c0ef","IPY_MODEL_0f59addf0d2f40309e025976c382cad8"],"layout":"IPY_MODEL_9422a87b93ab4473913e601da3a18689"}},"81b4a9a7cde64b17856b89dbd238c0ef":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_1ef6d64d40d8461d9e6adddd513089b8","max":2,"min":0,"orientation":"horizontal","style":"IPY_MODEL_324c2396f44f45c89d9ec264007ef9ff","value":2}},"85d217d6b45847869cea506db59e8b42":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_5d243712a1a545e99fa858b0cf19831d","max":2,"min":0,"orientation":"horizontal","style":"IPY_MODEL_96385fd98f304649ab5c4ae81333fb63","value":2}},"875758123e4f41f0b5c3fa0cd4fb47c6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9422a87b93ab4473913e601da3a18689":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"96385fd98f304649ab5c4ae81333fb63":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d409334237014614bf9ae742597d98ea":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d576a283e6424206ab4c25d809241c21":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d8a7714cd80d479e859b6ae31ebce7e5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d98918fae8174629b4819a1114f21202":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_1d03719518b8423099b8b68a92e449d7","IPY_MODEL_85d217d6b45847869cea506db59e8b42","IPY_MODEL_1d89705c74d34016bbc1e0601ead825c"],"layout":"IPY_MODEL_d576a283e6424206ab4c25d809241c21"}}},"version_major":2,"version_minor":0}}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install transformers peft accelerate bitsandbytes \\\n    -U --no-index --find-links /kaggle/input/lmsys-wheel-files","metadata":{"_kg_hide-input":false,"_kg_hide-output":true,"papermill":{"duration":31.479497,"end_time":"2024-07-10T01:13:41.690971","exception":false,"start_time":"2024-07-10T01:13:10.211474","status":"completed"},"scrolled":true,"tags":[],"execution":{"iopub.status.busy":"2024-08-05T04:31:05.925207Z","iopub.execute_input":"2024-08-05T04:31:05.925564Z","iopub.status.idle":"2024-08-05T04:31:36.361332Z","shell.execute_reply.started":"2024-08-05T04:31:05.925525Z","shell.execute_reply":"2024-08-05T04:31:36.360176Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import time\nfrom dataclasses import dataclass\nfrom concurrent.futures import ThreadPoolExecutor\nimport torch\nimport numpy as np\nimport pandas as pd\nfrom transformers import Gemma2ForSequenceClassification, GemmaTokenizerFast\nfrom transformers.data.data_collator import pad_without_fast_tokenizer_warning\nfrom peft import PeftModel\nfrom tqdm import tqdm\nimport os\nimport concurrent.futures\nfrom functools import partial","metadata":{"papermill":{"duration":19.200405,"end_time":"2024-07-10T01:14:00.90474","exception":false,"start_time":"2024-07-10T01:13:41.704335","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-08-05T04:31:36.363712Z","iopub.execute_input":"2024-08-05T04:31:36.364475Z","iopub.status.idle":"2024-08-05T04:31:56.113835Z","shell.execute_reply.started":"2024-08-05T04:31:36.364437Z","shell.execute_reply":"2024-08-05T04:31:56.113066Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"assert torch.cuda.device_count() == 2","metadata":{"papermill":{"duration":0.047799,"end_time":"2024-07-10T01:14:00.965921","exception":false,"start_time":"2024-07-10T01:14:00.918122","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-08-05T04:31:56.115004Z","iopub.execute_input":"2024-08-05T04:31:56.115585Z","iopub.status.idle":"2024-08-05T04:31:56.147406Z","shell.execute_reply.started":"2024-08-05T04:31:56.115555Z","shell.execute_reply":"2024-08-05T04:31:56.146666Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Configurations","metadata":{}},{"cell_type":"code","source":"@dataclass\nclass Config:\n    gemma_dir = '/kaggle/input/gemma-2/transformers/gemma-2-9b-it-4bit/1/gemma-2-9b-it-4bit'\n    lora_dir = '/kaggle/input/lmsys-gemma2-lora-weights/checkpoint-2524_normal/checkpoint-2524'\n    max_length = 1776\n    batch_size = 4\n    device = torch.device(\"cuda\")    \n    tta = True\n    spread_max_length = False\n\ncfg = Config()","metadata":{"papermill":{"duration":0.021338,"end_time":"2024-07-10T01:14:01.000606","exception":false,"start_time":"2024-07-10T01:14:00.979268","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-08-05T04:33:35.446504Z","iopub.execute_input":"2024-08-05T04:33:35.447202Z","iopub.status.idle":"2024-08-05T04:33:35.452725Z","shell.execute_reply.started":"2024-08-05T04:33:35.447160Z","shell.execute_reply":"2024-08-05T04:33:35.451748Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Load & pre-process Data ","metadata":{"papermill":{"duration":0.012663,"end_time":"2024-07-10T01:14:01.026248","exception":false,"start_time":"2024-07-10T01:14:01.013585","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"### Stage-1 重复/same case处理","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom functools import partial\nimport os\nimport concurrent.futures\nfrom tqdm import tqdm\n\ndef adjust_probabilities(prob_a, prob_b, prob_tie, threshold=0.9):\n    # 找出最大的概率\n    max_prob = max(prob_a, prob_b, prob_tie)\n    \n    if max_prob >= threshold:\n        if max_prob == prob_a:\n            return 0.9, 0.05, 0.05\n        elif max_prob == prob_b:\n            return 0.05, 0.9, 0.05\n        else:\n            return 0.05, 0.05, 0.9\n    else:\n        return prob_a, prob_b, prob_tie\n\ndef check_duplicates(row, all_data):\n    mask_exact = (all_data['prompt'] == row['prompt']) & \\\n                 (all_data['response_a'] == row['response_a']) & \\\n                 (all_data['response_b'] == row['response_b'])\n    \n    mask_swapped = (all_data['prompt'] == row['prompt']) & \\\n                   (all_data['response_a'] == row['response_b']) & \\\n                   (all_data['response_b'] == row['response_a'])\n    \n    exact_matches = all_data[mask_exact]\n    swapped_matches = all_data[mask_swapped]\n    \n    if len(exact_matches) + len(swapped_matches) > 0:\n        return swapped_matches, len(swapped_matches) > 0\n    \n    return None, False\n\ndef apply_check_duplicates(row, all_data):\n    result, has_swapped = check_duplicates(row, all_data)\n    if result is not None:\n        # 计算总和\n        sum_a = result['winner_model_a'].sum()\n        sum_b = result['winner_model_b'].sum()\n        sum_tie = result['winner_tie'].sum()\n        total = sum_a + sum_b + sum_tie\n        \n        # 计算概率\n        prob_a = sum_a / total\n        prob_b = sum_b / total\n        prob_tie = sum_tie / total\n        \n        # 调整概率\n        adj_a, adj_b, adj_tie = adjust_probabilities(prob_a, prob_b, prob_tie)\n        \n        if has_swapped:\n            return pd.Series({\n                'is_duplicate': True,\n                'winner_model_a': adj_b,  # 交换a和b\n                'winner_model_b': adj_a,\n                'winner_tie': adj_tie\n            })\n        else:\n            return pd.Series({\n                'is_duplicate': True,\n                'winner_model_a': adj_a,\n                'winner_model_b': adj_b,\n                'winner_tie': adj_tie\n            })\n    return pd.Series({'is_duplicate': False, 'winner_model_a': None, 'winner_model_b': None, 'winner_tie': None})\n\ndef parallel_check_duplicates(test_chunk, all_data):\n    return test_chunk.apply(lambda row: apply_check_duplicates(row, all_data), axis=1)","metadata":{"execution":{"iopub.status.busy":"2024-08-05T04:31:56.156950Z","iopub.execute_input":"2024-08-05T04:31:56.157265Z","iopub.status.idle":"2024-08-05T04:31:56.171833Z","shell.execute_reply.started":"2024-08-05T04:31:56.157237Z","shell.execute_reply":"2024-08-05T04:31:56.170943Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Load and preprocess data\ntest = pd.read_csv('/kaggle/input/lmsys-chatbot-arena/test.csv')\n# train = pd.read_csv('/kaggle/input/lmsys-chatbot-arena/train.csv')\n# test_0 = pd.read_csv('/kaggle/input/lmsys-chatbot-arena/test.csv')\n# test = test.iloc[0:10]  # 测试功能\n# test = pd.concat([test, test_0], axis=0)","metadata":{"execution":{"iopub.status.busy":"2024-08-05T04:31:56.172994Z","iopub.execute_input":"2024-08-05T04:31:56.173325Z","iopub.status.idle":"2024-08-05T04:31:56.194390Z","shell.execute_reply.started":"2024-08-05T04:31:56.173296Z","shell.execute_reply":"2024-08-05T04:31:56.193514Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"all_data_to_be_check = pd.read_csv('/kaggle/input/all-data-to-be-checked/lmsys-33k.csv')\n# all_data_to_be_check_1 = pd.read_csv('/kaggle/input/all-data-to-be-checked/train.csv')\n# all_data_to_be_check = pd.concat([all_data_to_be_check_0, all_data_to_be_check_1], axis=0)\n","metadata":{"execution":{"iopub.status.busy":"2024-08-05T04:31:56.195654Z","iopub.execute_input":"2024-08-05T04:31:56.196357Z","iopub.status.idle":"2024-08-05T04:31:57.346535Z","shell.execute_reply.started":"2024-08-05T04:31:56.196323Z","shell.execute_reply":"2024-08-05T04:31:57.345218Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 处理两个response相同的情况（保持不变）\nsame_response_mask = test[\"response_a\"] == test[\"response_b\"]\ntest.loc[same_response_mask, \"is_duplicate\"] = True\ntest.loc[same_response_mask, \"winner_model_a\"] = 0.05\ntest.loc[same_response_mask, \"winner_model_b\"] = 0.05\ntest.loc[same_response_mask, \"winner_tie\"] = 0.9","metadata":{"execution":{"iopub.status.busy":"2024-08-05T04:31:57.347580Z","iopub.execute_input":"2024-08-05T04:31:57.347846Z","iopub.status.idle":"2024-08-05T04:31:57.368136Z","shell.execute_reply.started":"2024-08-05T04:31:57.347823Z","shell.execute_reply":"2024-08-05T04:31:57.367229Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 并行处理重复检查\nprint(\"Checking for duplicates...\")\nnum_cores = 2 # os.cpu_count()  # 获取CPU核心数\n\n# 将test数据分成num_cores份\nchunk_size = len(test) // num_cores\ntest_chunks = [test[i:i+chunk_size] for i in range(0, len(test), chunk_size)]\n\n# 使用partial函数固定all_data_to_be_check参数\npartial_check = partial(parallel_check_duplicates, all_data=all_data_to_be_check)\n\n# 使用ProcessPoolExecutor\nwith concurrent.futures.ProcessPoolExecutor(max_workers=num_cores) as executor:\n    results = list(tqdm(executor.map(partial_check, test_chunks), total=len(test_chunks), desc=\"Processing chunks\"))\n\n# 合并结果\nduplicate_results = pd.concat(results)\n\n# 更新test数据框\ntest[['is_duplicate', 'winner_model_a', 'winner_model_b', 'winner_tie']] = duplicate_results\n\n# 创建包含重复和相同响应的submission_df\nduplicate_df = test[test['is_duplicate']][[\"id\", 'winner_model_a', 'winner_model_b', 'winner_tie']]\n\n# 准备需要推理的数据\ntest_for_inference = test[~test['is_duplicate']].copy()","metadata":{"execution":{"iopub.status.busy":"2024-08-05T04:31:57.369495Z","iopub.execute_input":"2024-08-05T04:31:57.369833Z","iopub.status.idle":"2024-08-05T04:31:58.252656Z","shell.execute_reply.started":"2024-08-05T04:31:57.369798Z","shell.execute_reply":"2024-08-05T04:31:58.251685Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Stage-2 Inference","metadata":{}},{"cell_type":"markdown","source":"# Tokenize","metadata":{"papermill":{"duration":0.012864,"end_time":"2024-07-10T01:14:01.148412","exception":false,"start_time":"2024-07-10T01:14:01.135548","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# 1. 数据准备和重复检验\ndef process_text(text: str) -> str:\n    return \" \".join(eval(text, {\"null\": \"\"}))\n\nfor df in [test, all_data_to_be_check]:\n    for col in ['prompt', 'response_a', 'response_b']:\n        df[col] = df[col].apply(process_text)","metadata":{"execution":{"iopub.status.busy":"2024-08-05T04:31:58.256319Z","iopub.execute_input":"2024-08-05T04:31:58.256616Z","iopub.status.idle":"2024-08-05T04:31:59.916110Z","shell.execute_reply.started":"2024-08-05T04:31:58.256588Z","shell.execute_reply":"2024-08-05T04:31:59.915071Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def tokenize(\n    tokenizer, prompt, response_a, response_b, max_length=cfg.max_length, spread_max_length=cfg.spread_max_length\n):\n    prompt = [\"<prompt>: \" + p for p in prompt]\n    response_a = [\"\\n\\n<response_a>: \" + r_a for r_a in response_a]\n    response_b = [\"\\n\\n<response_b>: \" + r_b for r_b in response_b]\n    if spread_max_length:\n        prompt = tokenizer(prompt, max_length=max_length//3, truncation=True, padding=False).input_ids\n        response_a = tokenizer(response_a, max_length=max_length//3, truncation=True, padding=False).input_ids\n        response_b = tokenizer(response_b, max_length=max_length//3, truncation=True, padding=False).input_ids\n        input_ids = [p + r_a + r_b for p, r_a, r_b in zip(prompt, response_a, response_b)]\n        attention_mask = [[1]* len(i) for i in input_ids]\n    else:\n        text = [p + r_a + r_b for p, r_a, r_b in zip(prompt, response_a, response_b)]\n        tokenized = tokenizer(text, max_length=max_length, truncation=True, padding=False)\n        input_ids = tokenized.input_ids\n        attention_mask = tokenized.attention_mask\n    return input_ids, attention_mask","metadata":{"papermill":{"duration":0.030237,"end_time":"2024-07-10T01:14:01.194318","exception":false,"start_time":"2024-07-10T01:14:01.164081","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-08-05T04:31:59.917407Z","iopub.execute_input":"2024-08-05T04:31:59.917701Z","iopub.status.idle":"2024-08-05T04:31:59.926335Z","shell.execute_reply.started":"2024-08-05T04:31:59.917676Z","shell.execute_reply":"2024-08-05T04:31:59.925276Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 准备推理数据\ntokenizer = GemmaTokenizerFast.from_pretrained(cfg.gemma_dir)\ntokenizer.add_eos_token = True\ntokenizer.padding_side = \"right\"\n\ndata = pd.DataFrame()\ndata[\"id\"] = test_for_inference[\"id\"]\ndata[\"input_ids\"], data[\"attention_mask\"] = tokenize(tokenizer, test_for_inference[\"prompt\"], test_for_inference[\"response_a\"], test_for_inference[\"response_b\"])\ndata[\"length\"] = data[\"input_ids\"].apply(len)\n\nif cfg.tta:\n    aug_data = pd.DataFrame()\n    aug_data[\"id\"] = test_for_inference[\"id\"]\n    aug_data['input_ids'], aug_data['attention_mask'] = tokenize(tokenizer, test_for_inference[\"prompt\"], test_for_inference[\"response_b\"], test_for_inference[\"response_a\"])\n    aug_data[\"length\"] = aug_data[\"input_ids\"].apply(len)","metadata":{"papermill":{"duration":1.169844,"end_time":"2024-07-10T01:14:02.377579","exception":false,"start_time":"2024-07-10T01:14:01.207735","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-08-05T04:31:59.927668Z","iopub.execute_input":"2024-08-05T04:31:59.927936Z","iopub.status.idle":"2024-08-05T04:32:01.057907Z","shell.execute_reply.started":"2024-08-05T04:31:59.927913Z","shell.execute_reply":"2024-08-05T04:32:01.056788Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Load model","metadata":{"papermill":{"duration":0.013054,"end_time":"2024-07-10T01:14:02.480304","exception":false,"start_time":"2024-07-10T01:14:02.46725","status":"completed"},"tags":[]}},{"cell_type":"code","source":"import torch.nn as nn\n\nclass CustomClassificationHead(nn.Module):\n    def __init__(self, config):\n        super().__init__()\n        self.fc1 = nn.Linear(config.hidden_size, config.hidden_size, bias=False)\n        self.fc2 = nn.Linear(config.hidden_size, config.hidden_size // 2, bias=False)\n        self.fc3 = nn.Linear(config.hidden_size // 2, config.num_labels, bias=False)\n\n    def forward(self, features):\n        x = self.fc1(features)\n        x = self.fc2(x)\n        x = self.fc3(x)\n        return x\n\n","metadata":{"execution":{"iopub.status.busy":"2024-08-05T04:32:01.059266Z","iopub.execute_input":"2024-08-05T04:32:01.059628Z","iopub.status.idle":"2024-08-05T04:32:01.069678Z","shell.execute_reply.started":"2024-08-05T04:32:01.059596Z","shell.execute_reply":"2024-08-05T04:32:01.068563Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Load base model on GPU 0\ndevice_0 = torch.device('cuda:0')\nmodel_0 = Gemma2ForSequenceClassification.from_pretrained(\n    cfg.gemma_dir,\n    device_map=device_0,\n    use_cache=False,\n    attn_implementation=\"sdpa\",\n\n)\n# 替换分类层\nmodel_0.score = CustomClassificationHead(model_0.config)\nmodel_0.score = model_0.score.to(device_0)\n\n\n# Load base model on GPU 1\ndevice_1 = torch.device('cuda:1')\nmodel_1 = Gemma2ForSequenceClassification.from_pretrained(\n    cfg.gemma_dir,\n    device_map=device_1,\n    use_cache=False,\n    attn_implementation=\"sdpa\",\n\n)\n# 替换分类层\nmodel_1.score = CustomClassificationHead(model_1.config)\nmodel_1.score = model_1.score.to(device_1)","metadata":{"papermill":{"duration":83.919146,"end_time":"2024-07-10T01:15:26.412583","exception":false,"start_time":"2024-07-10T01:14:02.493437","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-08-05T04:32:01.070718Z","iopub.execute_input":"2024-08-05T04:32:01.071144Z","iopub.status.idle":"2024-08-05T04:33:14.952000Z","shell.execute_reply.started":"2024-08-05T04:32:01.071110Z","shell.execute_reply":"2024-08-05T04:33:14.951179Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Load LoRA adapter","metadata":{"papermill":{"duration":0.013639,"end_time":"2024-07-10T01:15:26.440571","exception":false,"start_time":"2024-07-10T01:15:26.426932","status":"completed"},"tags":[]}},{"cell_type":"code","source":"model_0 = PeftModel.from_pretrained(model_0, cfg.lora_dir)\nmodel_1 = PeftModel.from_pretrained(model_1, cfg.lora_dir)","metadata":{"papermill":{"duration":1.265087,"end_time":"2024-07-10T01:15:27.719297","exception":false,"start_time":"2024-07-10T01:15:26.45421","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-08-05T04:33:39.331234Z","iopub.execute_input":"2024-08-05T04:33:39.331618Z","iopub.status.idle":"2024-08-05T04:33:49.130864Z","shell.execute_reply.started":"2024-08-05T04:33:39.331589Z","shell.execute_reply":"2024-08-05T04:33:49.130040Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Inference\n","metadata":{"papermill":{"duration":0.013989,"end_time":"2024-07-10T01:15:27.797512","exception":false,"start_time":"2024-07-10T01:15:27.783523","status":"completed"},"tags":[]}},{"cell_type":"code","source":"from tqdm import tqdm","metadata":{"execution":{"iopub.status.busy":"2024-08-05T04:33:49.132503Z","iopub.execute_input":"2024-08-05T04:33:49.132812Z","iopub.status.idle":"2024-08-05T04:33:49.137003Z","shell.execute_reply.started":"2024-08-05T04:33:49.132784Z","shell.execute_reply":"2024-08-05T04:33:49.136047Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"@torch.no_grad()\n@torch.cuda.amp.autocast()\n\n\ndef inference(df, model, device, batch_size=cfg.batch_size, max_length=cfg.max_length):\n    a_win, b_win, tie = [], [], []\n    \n    # 创建进度条\n    progress_bar = tqdm(total=len(df), desc=f\"Inference on {device}\", unit=\"sample\")\n    \n    for start_idx in range(0, len(df), batch_size):\n        end_idx = min(start_idx + batch_size, len(df))\n        tmp = df.iloc[start_idx:end_idx]\n        input_ids = tmp[\"input_ids\"].to_list()\n        attention_mask = tmp[\"attention_mask\"].to_list()\n        inputs = pad_without_fast_tokenizer_warning(\n            tokenizer,\n            {\"input_ids\": input_ids, \"attention_mask\": attention_mask},\n            padding=\"longest\",\n            pad_to_multiple_of=None,\n            return_tensors=\"pt\",\n        )\n        outputs = model(**inputs.to(device))\n        proba = outputs.logits.softmax(-1).cpu()\n        \n        a_win.extend(proba[:, 0].tolist())\n        b_win.extend(proba[:, 1].tolist())\n        tie.extend(proba[:, 2].tolist())\n        \n        # 更新进度条\n        progress_bar.update(len(tmp))\n    \n    # 关闭进度条\n    progress_bar.close()\n    \n    df[\"winner_model_a\"] = a_win\n    df[\"winner_model_b\"] = b_win\n    df[\"winner_tie\"] = tie\n    \n    return df","metadata":{"papermill":{"duration":0.026726,"end_time":"2024-07-10T01:15:27.838497","exception":false,"start_time":"2024-07-10T01:15:27.811771","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-08-05T04:33:49.138211Z","iopub.execute_input":"2024-08-05T04:33:49.138507Z","iopub.status.idle":"2024-08-05T04:33:49.149502Z","shell.execute_reply.started":"2024-08-05T04:33:49.138476Z","shell.execute_reply":"2024-08-05T04:33:49.148441Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Perform inference\nst = time.time()\n\ndata = data.sort_values(\"length\", ascending=False)\nsub_1 = data.iloc[0::2].copy()\nsub_2 = data.iloc[1::2].copy()\n\nwith ThreadPoolExecutor(max_workers=2) as executor:\n    results = executor.map(inference, (sub_1, sub_2), (model_0, model_1), (device_0, device_1))\n\nresult_df = pd.concat(list(results), axis=0)\nproba = result_df[[\"winner_model_a\", \"winner_model_b\", \"winner_tie\"]].values\n\nprint(f\"Inference elapsed time: {time.time() - st}\")","metadata":{"papermill":{"duration":4.598663,"end_time":"2024-07-10T01:15:32.45234","exception":false,"start_time":"2024-07-10T01:15:27.853677","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-08-05T04:33:49.151411Z","iopub.execute_input":"2024-08-05T04:33:49.151707Z","iopub.status.idle":"2024-08-05T04:33:53.957333Z","shell.execute_reply.started":"2024-08-05T04:33:49.151680Z","shell.execute_reply":"2024-08-05T04:33:53.956433Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if cfg.tta:\n    st = time.time()\n    aug_data = aug_data.sort_values(\"length\", ascending=False)\n    sub_1 = aug_data.iloc[0::2].copy()\n    sub_2 = aug_data.iloc[1::2].copy()\n\n    with ThreadPoolExecutor(max_workers=2) as executor:\n        results = executor.map(inference, (sub_1, sub_2), (model_0, model_1), (device_0, device_1))\n\n    tta_result_df = pd.concat(list(results), axis=0)\n    tta_proba = tta_result_df[[\"winner_model_b\", \"winner_model_a\", \"winner_tie\"]].values \n    proba = (proba + tta_proba) / 2\n\n    print(f\"TTA elapsed time: {time.time() - st}\")","metadata":{"papermill":{"duration":0.024559,"end_time":"2024-07-10T01:15:32.491283","exception":false,"start_time":"2024-07-10T01:15:32.466724","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-08-05T04:33:53.958667Z","iopub.execute_input":"2024-08-05T04:33:53.958970Z","iopub.status.idle":"2024-08-05T04:33:58.028689Z","shell.execute_reply.started":"2024-08-05T04:33:53.958944Z","shell.execute_reply":"2024-08-05T04:33:58.027713Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 5. 合并结果并生成最终的submission_df\nmask = proba > 1.0\nproba_processed = np.where(mask.any(axis=1)[:, np.newaxis], mask, proba)\n\nresult_df.loc[:, \"winner_model_a\"] = proba_processed[:, 0]\nresult_df.loc[:, \"winner_model_b\"] = proba_processed[:, 1]\nresult_df.loc[:, \"winner_tie\"] = proba_processed[:, 2]\n\ninference_df = result_df[[\"id\", 'winner_model_a', 'winner_model_b', 'winner_tie']]\n\n# 合并重复/相同响应的结果和推理结果\nsubmission_df = pd.concat([duplicate_df, inference_df])\n\n# 保存为 CSV\nsubmission_df.to_csv('submission.csv', index=False)\nprint(\"Submission file created.\")","metadata":{"execution":{"iopub.status.busy":"2024-08-05T04:33:58.029997Z","iopub.execute_input":"2024-08-05T04:33:58.030425Z","iopub.status.idle":"2024-08-05T04:33:58.045864Z","shell.execute_reply.started":"2024-08-05T04:33:58.030394Z","shell.execute_reply":"2024-08-05T04:33:58.045009Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission_df","metadata":{"execution":{"iopub.status.busy":"2024-08-05T04:33:58.047209Z","iopub.execute_input":"2024-08-05T04:33:58.047504Z","iopub.status.idle":"2024-08-05T04:33:58.062891Z","shell.execute_reply.started":"2024-08-05T04:33:58.047480Z","shell.execute_reply":"2024-08-05T04:33:58.062004Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}